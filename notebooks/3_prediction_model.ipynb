{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f0e23988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low-count categories\n",
    "df = df.loc[(df['MemberCity'] != 'None') &\n",
    "            (df['MemberCity'] != 'Unknown') &\n",
    "            (df['MemberCity'] != 'unk') &\n",
    "            (df['MemberCity'] != 'None') &\n",
    "            (df['MemberCity'] != 'Unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cae71c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low-count categories\n",
    "df = df.loc[(df['MemberProvince'] != 'None') &\n",
    "            (df['MemberProvince'] != 'Unknown') &\n",
    "            (df['MemberProvince'] != 'unk') &\n",
    "            (df['MemberProvince'] != 'None') &\n",
    "            (df['MemberProvince'] != 'Unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65ecfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low-count categories\n",
    "df = df.loc[(df['ClaimantAge'] != 'None') &\n",
    "            (df['ClaimantAge'] != 'Unknown') &\n",
    "            (df['ClaimantAge'] != 'unk') &\n",
    "            (df['ClaimantAge'] != 'None') &\n",
    "            (df['ClaimantAge'] != 'Unknown')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7c09f",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Describe Data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21de81b",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Load Dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b96e1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(config_data: dict) -> pd.DataFrame:\n",
    "    # Load set of data\n",
    "    x_train = util.pickle_load(config_data[\"train_set_path\"][0])\n",
    "    y_train = util.pickle_load(config_data[\"train_set_path\"][1])\n",
    "\n",
    "    x_valid = util.pickle_load(config_data[\"valid_set_path\"][0])\n",
    "    y_valid = util.pickle_load(config_data[\"valid_set_path\"][1])\n",
    "\n",
    "    x_test = util.pickle_load(config_data[\"test_set_path\"][0])\n",
    "    y_test = util.pickle_load(config_data[\"test_set_path\"][1])\n",
    "\n",
    "    # concatenate x and y each set\n",
    "    train_set = pd.concat([x_train, y_train], axis = 1)\n",
    "    valid_set = pd.concat([x_valid, y_valid], axis = 1)\n",
    "    test_set = pd.concat([x_test, y_test], axis = 1)\n",
    "\n",
    "    # return 3 set of data\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bf9d3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = load_dataset(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5710dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = train_set.reset_index(drop=True),  valid_set.reset_index(drop=True),test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e0c8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "\n",
    "# Divide the dataframe into independent and dependent variables\n",
    "X = df.drop(columns=[\"Label1\", \"Label2\"], axis=1)\n",
    "y = df[[\"Label1\", \"Label2\"]].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f17b8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values, y.values, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c2ec4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns for X and y variables\n",
    "X_cols = df.drop(columns=[\"Label1\", \"Label2\"]).columns\n",
    "y_cols = df[[\"Label1\", \"Label2\"]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a4738337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert X variable array to data frame\n",
    "def arr_to_dfx(arr):\n",
    "    return (pd.DataFrame(data=arr[0:,0:], index=[i for i in range(arr.shape[0])], columns=[X_cols[i] for i in range(len(X_cols))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a252cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert y variable array to data frame\n",
    "def arr_to_dfy(arr):\n",
    "    return (pd.DataFrame(data=arr[0:,0:], index=[i for i in range(arr.shape[0])], columns=[y_cols[i] for i in range(len(y_cols))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "456a9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert arrays to data frames for each variable\n",
    "X_train = arr_to_dfx(X_train)\n",
    "y_train = arr_to_dfy(y_train)\n",
    "\n",
    "X_test = arr_to_dfx(X_test)\n",
    "y_test = arr_to_dfy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f71007a",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "Apply one-hot encoder on categorical features. The parameter handle_unknown=\"ignore\" ensures that the model is robust during production as it ignores labels not seen in train set that are present in test set, thus avoiding any interruption during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99b76581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use One-Hot Encoding to perform fitting for categorical features in the train data\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\") # Ensure consistent results on unseen data\n",
    "ohe.fit(X_train[['DINLevel1ClassCode','ClaimSubmissionChannel','ClaimantGender','MemberProvince']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99609d88",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Clean the datasets and apply one-hot encoder to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "63d5aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_encode_column(column_series):\n",
    "    \"\"\"\n",
    "    Clean and encode a specific column.\n",
    "\n",
    "    \"\"\"\n",
    "    # Clean formatting issues\n",
    "    cleaned_column = column_series.str.lower()  # Convert to lowercase\n",
    "    cleaned_column = cleaned_column.str.replace(f'[{string.punctuation}0-9]', '', regex=True)  # Remove special characters and numbers\n",
    "    cleaned_column = cleaned_column.str.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "    # Calculate frequency of each value\n",
    "    freq = cleaned_column.value_counts() / len(cleaned_column)\n",
    "\n",
    "    # Replace original values with frequencies\n",
    "    encoded_column = cleaned_column.map(freq)\n",
    "\n",
    "    return encoded_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8bbd01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_MemberCity_train = clean_and_encode_column(X_train['MemberCity'])\n",
    "clean_MemberCity_test = clean_and_encode_column(X_test['MemberCity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd6c1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_MemberCity_train_enc = clean_MemberCity_train.to_frame(name='Clean_MemberCity')\n",
    "clean_MemberCity_test_enc = clean_MemberCity_test.to_frame(name = 'Clean_MemberCity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "358b2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, clean_MemberCity_train_enc], axis=1)\n",
    "X_test = pd.concat([X_test, clean_MemberCity_test_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e75b7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for pre-processing a dataframe\n",
    "def preprocess(dfr):\n",
    "    \n",
    "    dfr[['ReceivedDate','PaymentIssueDate', 'ServiceDate']] = dfr[['ReceivedDate','PaymentIssueDate', 'ServiceDate']].apply(pd.to_datetime, format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    " # Convert the dates to datetime format\n",
    "\n",
    "    \n",
    "    #submitted amout columns\n",
    "\n",
    "    submitted_amount_str = dfr['SubmittedAmount'].astype(str)\n",
    "    submitted_amount_str_no_quotes = submitted_amount_str.str.strip('\"')  # Remove double quotes\n",
    "    submitted_amount_numeric = pd.to_numeric(submitted_amount_str_no_quotes.str.replace('[\\$,()]', ''), errors='coerce')\n",
    "    submitted_amount_numeric.fillna(0, inplace=True)\n",
    "    dfr['SubmittedAmountNumeric'] = submitted_amount_numeric\n",
    "\n",
    "    # submitted_amount_str = dfr['SubmittedAmount'].astype(str)\n",
    "    # submitted_amount_numeric = pd.to_numeric(submitted_amount_str.str.replace('[\\$,()]', ''), errors='coerce')\n",
    "    # submitted_amount_numeric.fillna(0, inplace=True)\n",
    "    # dfr['SubmittedAmountNumeric'] = submitted_amount_numeric\n",
    "\n",
    "    #new columns\n",
    "    # Create new features from date format columns\n",
    "    dfr['ReceivedYear'] = dfr['ReceivedDate'].dt.year\n",
    "    dfr['ReceivedMonth'] = dfr['ReceivedDate'].dt.month\n",
    "    dfr['ReceivedDayOfWeek'] = dfr['ReceivedDate'].dt.dayofweek\n",
    "    dfr['PaymentYear'] = dfr['PaymentIssueDate'].dt.year\n",
    "    dfr['PaymentMonth'] = dfr['PaymentIssueDate'].dt.month\n",
    "    dfr['PaymentDayOfWeek'] = dfr['PaymentIssueDate'].dt.dayofweek\n",
    "    dfr['ServiceYear'] = dfr['ServiceDate'].dt.year \n",
    "    dfr['ServiceMonth'] = dfr['ServiceDate'].dt.month\n",
    "    dfr['ServiceDayOfWeek'] = dfr['ServiceDate'].dt.dayofweek\n",
    "\n",
    "    # Calculate 'member_claims_count' and 'member_avg_amount'\n",
    "    dfr['member_claims_count'] = dfr.groupby('MemberCity')['SubmittedAmountNumeric'].transform('count')\n",
    "    dfr['member_avg_amount'] = dfr.groupby('MemberCity')['SubmittedAmountNumeric'].transform('mean')\n",
    "\n",
    "    # Calculate 'member_claims_count' and 'member_avg_amount'\n",
    "    dfr['member_claims_count_by_province'] = dfr.groupby('MemberProvince')['SubmittedAmountNumeric'].transform('count')\n",
    "    dfr['member_avg_amount_by_province'] = dfr.groupby('MemberProvince')['SubmittedAmountNumeric'].transform('mean')\n",
    "\n",
    "    # Create new features that represent the ratio of 'SubmittedAmount' to 'member_claims_count'\n",
    "    dfr['AmountToClaimsCountRatio'] = dfr['SubmittedAmountNumeric'] / dfr['member_claims_count']\n",
    "    \n",
    "    subset = dfr[['DINLevel1ClassCode','ClaimSubmissionChannel','ClaimantGender','MemberProvince']] # Create a subset of relevant categorical columns\n",
    "    feature_arr = ohe.transform(subset).toarray() # Transform the dataframe using one-hot encoding\n",
    "    feature_labels = ohe.get_feature_names_out() # Extract the encoded feature labels\n",
    "\n",
    "    features = pd.DataFrame(feature_arr, columns=feature_labels, index=subset.index) # Create a dataframe for feature array & labels post-encoding\n",
    "\n",
    "\n",
    "    dfr = pd.concat([dfr,features], axis=1) # Concat the (now) feature dataframe with the argument dataframe\n",
    "\n",
    "    drop_columns = ['DINLevel1ClassCode','ExpenseType','ClaimSubmissionChannel', 'ClaimantAge', 'ClaimantGender', \\\n",
    "                   'MemberProvince', 'SubmittedAmount', ]\n",
    "\n",
    "    dfr = dfr.drop(columns= drop_columns) # Drop redundant columns\n",
    "    \n",
    "    return dfr # Return the pre-processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a00962e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReceivedDate</th>\n",
       "      <th>MemberIDscrambled</th>\n",
       "      <th>FacilityIDscrambled</th>\n",
       "      <th>MemberCity</th>\n",
       "      <th>PaymentIssueDate</th>\n",
       "      <th>ServiceDate</th>\n",
       "      <th>UniqueClaimCount</th>\n",
       "      <th>Clean_MemberCity</th>\n",
       "      <th>SubmittedAmountNumeric</th>\n",
       "      <th>ReceivedYear</th>\n",
       "      <th>ReceivedMonth</th>\n",
       "      <th>ReceivedDayOfWeek</th>\n",
       "      <th>PaymentYear</th>\n",
       "      <th>PaymentMonth</th>\n",
       "      <th>PaymentDayOfWeek</th>\n",
       "      <th>ServiceYear</th>\n",
       "      <th>ServiceMonth</th>\n",
       "      <th>ServiceDayOfWeek</th>\n",
       "      <th>member_claims_count</th>\n",
       "      <th>member_avg_amount</th>\n",
       "      <th>member_claims_count_by_province</th>\n",
       "      <th>member_avg_amount_by_province</th>\n",
       "      <th>AmountToClaimsCountRatio</th>\n",
       "      <th>DINLevel1ClassCode_A</th>\n",
       "      <th>DINLevel1ClassCode_B</th>\n",
       "      <th>DINLevel1ClassCode_C</th>\n",
       "      <th>DINLevel1ClassCode_D</th>\n",
       "      <th>ClaimSubmissionChannel_Mobile</th>\n",
       "      <th>ClaimSubmissionChannel_Other Unclassified</th>\n",
       "      <th>ClaimSubmissionChannel_Paper</th>\n",
       "      <th>ClaimSubmissionChannel_Pay Direct Drug</th>\n",
       "      <th>ClaimSubmissionChannel_Web</th>\n",
       "      <th>ClaimantGender_F</th>\n",
       "      <th>ClaimantGender_M</th>\n",
       "      <th>ClaimantGender_U</th>\n",
       "      <th>MemberProvince_AL</th>\n",
       "      <th>MemberProvince_ALTA</th>\n",
       "      <th>MemberProvince_BC</th>\n",
       "      <th>MemberProvince_DC</th>\n",
       "      <th>MemberProvince_FL</th>\n",
       "      <th>MemberProvince_MAN</th>\n",
       "      <th>MemberProvince_NB</th>\n",
       "      <th>MemberProvince_NFLD</th>\n",
       "      <th>MemberProvince_NS</th>\n",
       "      <th>MemberProvince_NU</th>\n",
       "      <th>MemberProvince_NWT</th>\n",
       "      <th>MemberProvince_ONT</th>\n",
       "      <th>MemberProvince_PEI</th>\n",
       "      <th>MemberProvince_QUE</th>\n",
       "      <th>MemberProvince_SASK</th>\n",
       "      <th>MemberProvince_TX</th>\n",
       "      <th>MemberProvince_YUK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>37567</td>\n",
       "      <td>5182</td>\n",
       "      <td>Deer Lake</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>37580</td>\n",
       "      <td>2758</td>\n",
       "      <td>Airdrie</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>22027</td>\n",
       "      <td>3746</td>\n",
       "      <td>ORLEANS</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38508.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>37581</td>\n",
       "      <td>331</td>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2942.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38508.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>37582</td>\n",
       "      <td>4215</td>\n",
       "      <td>LEDUC</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ReceivedDate MemberIDscrambled FacilityIDscrambled MemberCity  \\\n",
       "0   2023-01-03             37567                5182  Deer Lake   \n",
       "1   2023-01-03             37580                2758    Airdrie   \n",
       "2   2023-01-03             22027                3746    ORLEANS   \n",
       "3   2023-01-03             37581                 331     OTTAWA   \n",
       "4   2023-01-03             37582                4215      LEDUC   \n",
       "\n",
       "  PaymentIssueDate ServiceDate UniqueClaimCount  Clean_MemberCity  \\\n",
       "0              NaT  2023-01-02                1          0.000162   \n",
       "1       2023-12-02  2023-12-02                1          0.002216   \n",
       "2       2023-01-03  2023-01-03                1          0.008481   \n",
       "3       2023-01-03  2023-01-03                1          0.036603   \n",
       "4       2023-01-03  2023-01-03                1          0.000951   \n",
       "\n",
       "   SubmittedAmountNumeric  ReceivedYear  ReceivedMonth  ReceivedDayOfWeek  \\\n",
       "0                     0.0        2023.0            1.0                1.0   \n",
       "1                     0.0        2023.0            1.0                1.0   \n",
       "2                     0.0        2023.0            1.0                1.0   \n",
       "3                     0.0        2023.0            1.0                1.0   \n",
       "4                     0.0        2023.0            1.0                1.0   \n",
       "\n",
       "   PaymentYear  PaymentMonth  PaymentDayOfWeek  ServiceYear  ServiceMonth  \\\n",
       "0          NaN           NaN               NaN       2023.0           1.0   \n",
       "1       2023.0          12.0               5.0       2023.0          12.0   \n",
       "2       2023.0           1.0               1.0       2023.0           1.0   \n",
       "3       2023.0           1.0               1.0       2023.0           1.0   \n",
       "4       2023.0           1.0               1.0       2023.0           1.0   \n",
       "\n",
       "   ServiceDayOfWeek  member_claims_count  member_avg_amount  \\\n",
       "0               0.0                  2.0                0.0   \n",
       "1               5.0                 56.0                0.0   \n",
       "2               1.0                709.0                0.0   \n",
       "3               1.0               2942.0                0.0   \n",
       "4               1.0                 50.0                0.0   \n",
       "\n",
       "   member_claims_count_by_province  member_avg_amount_by_province  \\\n",
       "0                           1428.0                            0.0   \n",
       "1                           9242.0                            0.0   \n",
       "2                          38508.0                            0.0   \n",
       "3                          38508.0                            0.0   \n",
       "4                           9242.0                            0.0   \n",
       "\n",
       "   AmountToClaimsCountRatio  DINLevel1ClassCode_A  DINLevel1ClassCode_B  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "\n",
       "   DINLevel1ClassCode_C  DINLevel1ClassCode_D  ClaimSubmissionChannel_Mobile  \\\n",
       "0                   0.0                   1.0                            0.0   \n",
       "1                   0.0                   1.0                            0.0   \n",
       "2                   0.0                   1.0                            0.0   \n",
       "3                   0.0                   1.0                            0.0   \n",
       "4                   1.0                   0.0                            0.0   \n",
       "\n",
       "   ClaimSubmissionChannel_Other Unclassified  ClaimSubmissionChannel_Paper  \\\n",
       "0                                        0.0                           0.0   \n",
       "1                                        0.0                           0.0   \n",
       "2                                        0.0                           0.0   \n",
       "3                                        0.0                           0.0   \n",
       "4                                        0.0                           0.0   \n",
       "\n",
       "   ClaimSubmissionChannel_Pay Direct Drug  ClaimSubmissionChannel_Web  \\\n",
       "0                                     0.0                         1.0   \n",
       "1                                     1.0                         0.0   \n",
       "2                                     1.0                         0.0   \n",
       "3                                     1.0                         0.0   \n",
       "4                                     1.0                         0.0   \n",
       "\n",
       "   ClaimantGender_F  ClaimantGender_M  ClaimantGender_U  MemberProvince_AL  \\\n",
       "0               1.0               0.0               0.0                0.0   \n",
       "1               1.0               0.0               0.0                0.0   \n",
       "2               1.0               0.0               0.0                0.0   \n",
       "3               1.0               0.0               0.0                0.0   \n",
       "4               1.0               0.0               0.0                0.0   \n",
       "\n",
       "   MemberProvince_ALTA  MemberProvince_BC  MemberProvince_DC  \\\n",
       "0                  0.0                0.0                0.0   \n",
       "1                  1.0                0.0                0.0   \n",
       "2                  0.0                0.0                0.0   \n",
       "3                  0.0                0.0                0.0   \n",
       "4                  1.0                0.0                0.0   \n",
       "\n",
       "   MemberProvince_FL  MemberProvince_MAN  MemberProvince_NB  \\\n",
       "0                0.0                 0.0                0.0   \n",
       "1                0.0                 0.0                0.0   \n",
       "2                0.0                 0.0                0.0   \n",
       "3                0.0                 0.0                0.0   \n",
       "4                0.0                 0.0                0.0   \n",
       "\n",
       "   MemberProvince_NFLD  MemberProvince_NS  MemberProvince_NU  \\\n",
       "0                  1.0                0.0                0.0   \n",
       "1                  0.0                0.0                0.0   \n",
       "2                  0.0                0.0                0.0   \n",
       "3                  0.0                0.0                0.0   \n",
       "4                  0.0                0.0                0.0   \n",
       "\n",
       "   MemberProvince_NWT  MemberProvince_ONT  MemberProvince_PEI  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 1.0                 0.0   \n",
       "3                 0.0                 1.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   MemberProvince_QUE  MemberProvince_SASK  MemberProvince_TX  \\\n",
       "0                 0.0                  0.0                0.0   \n",
       "1                 0.0                  0.0                0.0   \n",
       "2                 0.0                  0.0                0.0   \n",
       "3                 0.0                  0.0                0.0   \n",
       "4                 0.0                  0.0                0.0   \n",
       "\n",
       "   MemberProvince_YUK  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode and pre-process the train set\n",
    "'MemberProvince_nan'\n",
    "X_train = preprocess(X_train).drop(columns=['MemberProvince_nan'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee518c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "179d1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and pre-process the test set\n",
    "X_test = preprocess(X_test).drop(columns=['MemberProvince_nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f81b8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['ReceivedDate', 'MemberIDscrambled', 'FacilityIDscrambled',\n",
    "       'MemberCity', 'PaymentIssueDate', 'ServiceDate', 'UniqueClaimCount',\n",
    "       'Clean_MemberCity', 'SubmittedAmountNumeric']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c8c7f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "X_test.drop(columns=columns_to_drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d8fe6",
   "metadata": {},
   "source": [
    "This procedure efficiently handled NaNs without having to remove all of them individually. Remove null values from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c243cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReceivedYear                                 27917\n",
       "ReceivedMonth                                27917\n",
       "ReceivedDayOfWeek                            27917\n",
       "PaymentYear                                  29682\n",
       "PaymentMonth                                 29682\n",
       "PaymentDayOfWeek                             29682\n",
       "ServiceYear                                  30097\n",
       "ServiceMonth                                 30097\n",
       "ServiceDayOfWeek                             30097\n",
       "member_claims_count                            107\n",
       "member_avg_amount                              107\n",
       "member_claims_count_by_province                 51\n",
       "member_avg_amount_by_province                   51\n",
       "AmountToClaimsCountRatio                       107\n",
       "DINLevel1ClassCode_A                             0\n",
       "DINLevel1ClassCode_B                             0\n",
       "DINLevel1ClassCode_C                             0\n",
       "DINLevel1ClassCode_D                             0\n",
       "ClaimSubmissionChannel_Mobile                    0\n",
       "ClaimSubmissionChannel_Other Unclassified        0\n",
       "ClaimSubmissionChannel_Paper                     0\n",
       "ClaimSubmissionChannel_Pay Direct Drug           0\n",
       "ClaimSubmissionChannel_Web                       0\n",
       "ClaimantGender_F                                 0\n",
       "ClaimantGender_M                                 0\n",
       "ClaimantGender_U                                 0\n",
       "MemberProvince_AL                                0\n",
       "MemberProvince_ALTA                              0\n",
       "MemberProvince_BC                                0\n",
       "MemberProvince_DC                                0\n",
       "MemberProvince_FL                                0\n",
       "MemberProvince_MAN                               0\n",
       "MemberProvince_NB                                0\n",
       "MemberProvince_NFLD                              0\n",
       "MemberProvince_NS                                0\n",
       "MemberProvince_NU                                0\n",
       "MemberProvince_NWT                               0\n",
       "MemberProvince_ONT                               0\n",
       "MemberProvince_PEI                               0\n",
       "MemberProvince_QUE                               0\n",
       "MemberProvince_SASK                              0\n",
       "MemberProvince_TX                                0\n",
       "MemberProvince_YUK                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null value counts again\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff567f",
   "metadata": {},
   "source": [
    "# TRANSFORM BOOLEAN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "37e477b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[['Label1', 'Label2']] = y_train[['Label1', 'Label2']].replace({True: 1, False: 0})\n",
    "y_test[['Label1', 'Label2']] = y_test[['Label1', 'Label2']].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "278ff687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs after join X and y variables for train and test sets separately\n",
    "train_joined = X_train.join(y_train).dropna()\n",
    "test_joined = X_test.join(y_test).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af5b2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y variables for train and test sets again\n",
    "X_train = train_joined.iloc[:, :-2]\n",
    "y_train = train_joined.iloc[:, -2:]\n",
    "\n",
    "X_test = test_joined.iloc[:, :-2]\n",
    "y_test = test_joined.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1639842",
   "metadata": {},
   "source": [
    "## Model development\n",
    "\n",
    "### DecisionTreeClassifier along with OneVsRestClassifier for multi-label classification model\n",
    "\n",
    "Use `DecisionTreeClassifier()` for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50202e12",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning\n",
    "Use `RandomizedSearchCV()` with a grid of parameters to find the optimal hyper-parameters for the model. The parameter error_score=0 ensures that fitting during cross-validation is uninterrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70501de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'splitter': 'best', 'max_leaf_nodes': 61, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define a grid of parameters\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [*range(2, 10, 1)],\n",
    "    'max_leaf_nodes': [*range(1, 100, 2)],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Use Randomized Search with 5 fold cross-validation to find optimal hyper-parameters\n",
    "CV_model_dt = RandomizedSearchCV(estimator=dtc, param_distributions=param_grid, cv=5, error_score=0, verbose=1, random_state=42)\n",
    "CV_model_dt.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal hyperparameters after randomized search cross-validation\n",
    "print(CV_model_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "10443ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028001</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>best</td>\n",
       "      <td>61</td>\n",
       "      <td>log2</td>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 61, 'ma...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.833705</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025394</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>best</td>\n",
       "      <td>73</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 73, 'ma...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.833705</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>best</td>\n",
       "      <td>93</td>\n",
       "      <td>auto</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 93, 'ma...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020602</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>best</td>\n",
       "      <td>67</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 67, 'ma...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.833705</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022209</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>best</td>\n",
       "      <td>27</td>\n",
       "      <td>log2</td>\n",
       "      <td>8</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 27, 'ma...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.833705</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>best</td>\n",
       "      <td>45</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 45, 'ma...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.833705</td>\n",
       "      <td>0.332591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021426</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>random</td>\n",
       "      <td>71</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'max_leaf_nodes': 71, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969329</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.827570</td>\n",
       "      <td>0.329738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>random</td>\n",
       "      <td>19</td>\n",
       "      <td>log2</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'max_leaf_nodes': 19, '...</td>\n",
       "      <td>0.994249</td>\n",
       "      <td>0.992332</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>0.992241</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.828246</td>\n",
       "      <td>0.329862</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.021001</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>best</td>\n",
       "      <td>31</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'max_leaf_nodes': 31, 'ma...</td>\n",
       "      <td>0.991511</td>\n",
       "      <td>0.986125</td>\n",
       "      <td>0.989868</td>\n",
       "      <td>0.988407</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.824887</td>\n",
       "      <td>0.328187</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019707</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>random</td>\n",
       "      <td>85</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>7</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'max_leaf_nodes': 85, '...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999452</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.833595</td>\n",
       "      <td>0.332536</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.028001      0.002969         0.006808        0.000735   \n",
       "1       0.025394      0.007349         0.005996        0.001100   \n",
       "2       0.007819      0.001297         0.000000        0.000000   \n",
       "3       0.020602      0.003047         0.005409        0.000501   \n",
       "4       0.022209      0.003137         0.005388        0.000501   \n",
       "5       0.021008      0.002279         0.005797        0.000401   \n",
       "6       0.021426      0.002812         0.005381        0.000493   \n",
       "7       0.018398      0.002423         0.005194        0.000405   \n",
       "8       0.021001      0.002531         0.005989        0.000668   \n",
       "9       0.019707      0.001783         0.005391        0.000477   \n",
       "\n",
       "  param_splitter param_max_leaf_nodes param_max_features param_max_depth  \\\n",
       "0           best                   61               log2               4   \n",
       "1           best                   73               sqrt               6   \n",
       "2           best                   93               auto               4   \n",
       "3           best                   67               sqrt               3   \n",
       "4           best                   27               log2               8   \n",
       "5           best                   45               sqrt               5   \n",
       "6         random                   71               sqrt               4   \n",
       "7         random                   19               log2               3   \n",
       "8           best                   31               sqrt               2   \n",
       "9         random                   85               sqrt               7   \n",
       "\n",
       "  param_criterion                                             params  \\\n",
       "0            gini  {'splitter': 'best', 'max_leaf_nodes': 61, 'ma...   \n",
       "1         entropy  {'splitter': 'best', 'max_leaf_nodes': 73, 'ma...   \n",
       "2         entropy  {'splitter': 'best', 'max_leaf_nodes': 93, 'ma...   \n",
       "3            gini  {'splitter': 'best', 'max_leaf_nodes': 67, 'ma...   \n",
       "4         entropy  {'splitter': 'best', 'max_leaf_nodes': 27, 'ma...   \n",
       "5         entropy  {'splitter': 'best', 'max_leaf_nodes': 45, 'ma...   \n",
       "6         entropy  {'splitter': 'random', 'max_leaf_nodes': 71, '...   \n",
       "7         entropy  {'splitter': 'random', 'max_leaf_nodes': 19, '...   \n",
       "8            gini  {'splitter': 'best', 'max_leaf_nodes': 31, 'ma...   \n",
       "9            gini  {'splitter': 'random', 'max_leaf_nodes': 85, '...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           1.000000           1.000000           1.000000           1.000000   \n",
       "1           1.000000           1.000000           1.000000           1.000000   \n",
       "2           0.000000           0.000000           0.000000           0.000000   \n",
       "3           1.000000           1.000000           1.000000           1.000000   \n",
       "4           1.000000           1.000000           1.000000           1.000000   \n",
       "5           1.000000           1.000000           1.000000           1.000000   \n",
       "6           1.000000           1.000000           1.000000           0.969329   \n",
       "7           0.994249           0.992332           0.993884           0.992241   \n",
       "8           0.991511           0.986125           0.989868           0.988407   \n",
       "9           1.000000           1.000000           1.000000           0.999452   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.168523         0.833705        0.332591                1  \n",
       "1           0.168523         0.833705        0.332591                1  \n",
       "2           0.000000         0.000000        0.000000               10  \n",
       "3           0.168523         0.833705        0.332591                1  \n",
       "4           0.168523         0.833705        0.332591                1  \n",
       "5           0.168523         0.833705        0.332591                1  \n",
       "6           0.168523         0.827570        0.329738                8  \n",
       "7           0.168523         0.828246        0.329862                7  \n",
       "8           0.168523         0.824887        0.328187                9  \n",
       "9           0.168523         0.833595        0.332536                6  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the fits/results from cross validation\n",
    "pd.DataFrame.from_dict(CV_model_dt.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "73a0049d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=4, max_features=&#x27;log2&#x27;, max_leaf_nodes=61,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, max_features=&#x27;log2&#x27;, max_leaf_nodes=61,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, max_features='log2', max_leaf_nodes=61,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best estimator that gave the highest score/minimum loss\n",
    "CV_model_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fb7cd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit the model with the optimal parameters\n",
    "clf = CV_model_dt.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034b713",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "Display top 10 features for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4fb43907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (22,12)\n",
    "feat_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1ec48",
   "metadata": {},
   "source": [
    "Display feature importance for all the features. More than half the features seem to not have contributed anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ce4dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importances = pd.Series(clf.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(30).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf658e7",
   "metadata": {},
   "source": [
    "## Metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2470ca1",
   "metadata": {},
   "source": [
    "**Zero-one loss**\n",
    "\n",
    "Zero-one loss returns the fraction of misclassifications. The best performance is 0. In multilabel classification, the `zero_one_loss()` function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2bc6c5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008832188420019316"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the zero-one classification loss\n",
    "zero_one_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69704636",
   "metadata": {},
   "source": [
    "**Hamming loss**\n",
    "\n",
    "The Hamming loss is the fraction of labels that are incorrectly predicted. In multilabel classification, the Hamming loss is different from the subset zero-one loss. The zero-one loss considers the entire set of labels for a given sample incorrect if it does not entirely match the true set of labels. Hamming loss is more forgiving in that it penalizes only the individual labels. It is always between 0 and 1, lower being better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ca8d22ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00044160942100098134"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the average Hamming loss\n",
    "hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e857e",
   "metadata": {},
   "source": [
    "**Exact Match Ratio and Hamming Loss for each segment using OneVsRestClassifier as a wrapper class**\n",
    "\n",
    "With the use of model pipeline, decompose this multi-label task into multiple independent binary classification problems (one per category). Using \"one vs rest\" strategy, build multiple independent classifiers and, for each unseen instance, display the desired metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2133ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label1:\n",
      "Exact Match Ratio: 1.0\n",
      "Hamming Loss: 0.0\n",
      "\n",
      "Label2:\n",
      "Exact Match Ratio: 0.9991167811579981\n",
      "Hamming Loss: 0.0008832188420019627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using pipeline to apply decision tree classifier with one vs rest classifier as a wrapper\n",
    "dt_pipeline = Pipeline([('clf', OneVsRestClassifier(clf, n_jobs=-1))])\n",
    "\n",
    "# Loop over each segment\n",
    "for category in y_train.columns:\n",
    "    print('{}:'.format(category))\n",
    "    \n",
    "    # Fit the model to the data\n",
    "    dt_pipeline.fit(X_train, y_train[category])\n",
    "    \n",
    "    # Calculate and display metrics\n",
    "    dt_pred = dt_pipeline.predict(X_test)\n",
    "\n",
    "    print('Exact Match Ratio: {}'.format(accuracy_score(y_test[category], dt_pred)))\n",
    "    print('Hamming Loss: {}\\n'.format(hamming_loss(y_test[category], dt_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abecbbf",
   "metadata": {},
   "source": [
    "### Overfitting can be countered by Pruning the tree: This means cutting off some branches of the tree that are too complex or too specific. Pruning can be done either before or after the tree is fully grown, by using different criteria such as the minimum number of samples in a node, the maximum depth of the tree, or the information gain of a split. Pruning can reduce the variance of the model and improve its performance on the test data\n",
    "### Setting a minimum sample split: This means setting a minimum number of samples that are required to split a node. This can prevent the tree from growing too deep and creating nodes that are based on very few samples. Setting a minimum sample split can also reduce the computational cost of the model and avoid overfitting\n",
    "### Setting a minimum leaf samples threshold: This means setting a minimum number of samples that are required to be in a leaf node. This can prevent the tree from creating leaves that are too pure or too specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13d2dd",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Display a multi-label confusion matrix as the model seems to suffer from overfitting when the metrics are computed individually for each segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a72ee6",
   "metadata": {},
   "source": [
    "### Use Multi-Output Classifier wrapper with Decision Tree Classifier to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "26918d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[12812,     0],\n",
       "        [    0,  7568]],\n",
       "\n",
       "       [[19066,     0],\n",
       "        [    0,  1314]]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Multi-Output Classifier wrapper with Decision Tree Classifier to get predictions\n",
    "clfr = MultiOutputClassifier(dtc)\n",
    "clfr.fit(X_train, y_train)\n",
    "pred = clfr.predict(X_test)\n",
    "\n",
    "# Compute and display the multi-label confusion matrix\n",
    "multilabel_confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "276c221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.99075405e-04],\n",
       "       [0.00000000e+00, 1.99075405e-04],\n",
       "       [0.00000000e+00, 1.99075405e-04],\n",
       "       ...,\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use One vs Rest Classifier wrapper with Decision Tree Classifier to get predicted probabilities for each segment\n",
    "clf_prob = OneVsRestClassifier(clf)\n",
    "clf_prob.fit(X_train, y_train)\n",
    "prob = clf_prob.predict_proba(X_test)\n",
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a90aeebcf29d64a654773811cc170cb25061cb2498f10ac689db374c7bf325de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
